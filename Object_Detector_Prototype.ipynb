{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_Detector_Prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMvsFSWvNduxgacXffJP3Mv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arifsoul/object-detector-prototype/blob/main/Object_Detector_Prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2alXc7hJTsTR"
      },
      "source": [
        "# **A. PENGENALAN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3wWp14fZSMM"
      },
      "source": [
        "## 1. Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35gAmELeZVHe"
      },
      "source": [
        "## 2. Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTrqxQreO81N"
      },
      "source": [
        "# **B. PERSIAPAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToVgkRXzAaQb"
      },
      "source": [
        "#@title Jalankan untuk menghubungkan dengan akun *google drive* anda! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMvsyAO4DNOr"
      },
      "source": [
        "\n",
        "\n",
        "> **Perintah diatas harus dijalankan setiap akan memulai menggunakan *prototype***\n",
        "\n",
        "> **disarankan menggunakan akun email UNY yang mempunyai kapasitas besar**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3tQQtlP4xRY"
      },
      "source": [
        "## 1. Pembuatan direktori kerja \n",
        "\n",
        "Direktori kerja dilakukan dengan menghubungkan akun *google drive*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j08T1Pkt47tP"
      },
      "source": [
        "#@title Buat direktori kerja! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/arifsoul/pendeteksi-objek.git\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVWTadhPEaL5"
      },
      "source": [
        "> Tahap pembuatan direktori kerja dilakukan sekali ketika pertama kali menggunakan *prototype* ini atau jika ingin mengganti akun *google drive* anda\n",
        "\n",
        "\n",
        "> Lewati tahapan ini jika anda sudah membuat direktori kerja sebelumnya\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZNmjowV9_H7"
      },
      "source": [
        "\n",
        "## 2. Pengumpulan *Dataset*\n",
        "\n",
        "Untuk Mengumpulkan *dataset* diperlukan gambar yang telah dilabeli berdasarkan objek yang ingin di deteksi\n",
        "\n",
        "> Data label di simpan dalam file berformat \".xml\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMKM50ZYTCKL"
      },
      "source": [
        "#@title Pelabelan Mandiri { vertical-output: true, display-mode: \"form\" }\n",
        "from IPython.display import Image\n",
        "Image(url='https://github.com/SkalskiP/make-sense/raw/develop/examples/demo-base.gif')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0_hIhWQUEq5"
      },
      "source": [
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.makesense.ai/\"><img src=\"https://www.makesense.ai/make-sense-ico-transparent.png\"</a>\n",
        "\n",
        "**Mulai Pelabelan**\n",
        "\n",
        "\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAa75xtl4RZX"
      },
      "source": [
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"right\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/models\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />Kode Sumber</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq86mRCJ5yZl"
      },
      "source": [
        "#  **C. PELATIHAN *(TRAINING)***\n",
        "> Proses pelatihan dilakukan untuk memperoleh file *Inference Graph* berformat \".pb\" yang akan digunakan untuk *deployment* pada sistem pendeteksi objek\n",
        "\n",
        "Tahapan yang perlu dilakukan antara lain:\n",
        "\n",
        "1. *Install Tensorflow Object detection API* dan *packages* yang dibutuhkan\n",
        "2. Persiapan file *TFrecord*\n",
        "3. Konfigurasi *training pipeline*\n",
        "4. *Transfer Learning* dan *Monitoring*\n",
        "5. Pengujian pendeteksi objek pada gambar menggunakan *checkpoint*\n",
        "6. *Export Inference Graph* yang telah di training berdasarkan *checkpoint*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxXgQCDGSpvV"
      },
      "source": [
        "## 1. *Install Tensorflow Object detection API* dan *packages* yang dibutuhkan\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0vw1Q8KFSxS"
      },
      "source": [
        "#@title Jalankan untuk *Install!* { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "Versi_Tensorflow = \"1\" #@param [\"1\", \"2\"] {allow-input: true}\n",
        "version = Versi_Tensorflow +\".x\"\n",
        "%tensorflow_version $version\n",
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython\n",
        "!pip install tf_slim \n",
        "!pip install lvis\n",
        "!pip install numpy\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        " \n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/MyDrive/pendeteksi-objek/models/research/:/content/drive/MyDrive/pendeteksi-objek/models/research/slim'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mybLs1CF-PsL"
      },
      "source": [
        "## 2. Persiapan file TFrecord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCEVi6p3CvM"
      },
      "source": [
        "###Masukkan nama folder dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL2SFmR_Qpn_"
      },
      "source": [
        "#@title Ketik nama folder dataset atau pilih jenis pendeteksi dari dataset yang sudah disediakan!  { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "\n",
        "Pendeteksi = \"Masker\" #@param [\"Masker\", \"Handphone\", \"Bola\"] {allow-input: true}\n",
        "repo_url = 'https://github.com/arifsoul/' + Pendeteksi\n",
        "\n",
        "import os\n",
        "\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "!git pull\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YirlKxm4ZZxt"
      },
      "source": [
        "#@title *Convert* file .xml ke .csv! { vertical-output: true, display-mode: \"form\" }\n",
        "Nama_Folder_Anotasi = \"annotations\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "# Konversikan anotasi pada folder train yang berupa file xml ke dalam satu csv file,\n",
        "# Buat file `label_map.pbtxt` kepada folder `data/`.\n",
        "!python xml_to_csv.py -i $Pendeteksi/gambar -o $Pendeteksi/$Nama_Folder_Anotasi/dataset_labels.csv -l $Pendeteksi/$Nama_Folder_Anotasi\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tC4ldkYVC-g"
      },
      "source": [
        "#@title *Split* data *train* dan *test* { vertical-output: true, display-mode: \"form\" }\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek/$Pendeteksi/$Nama_Folder_Anotasi\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "df = pd.read_csv('dataset_labels.csv')\n",
        "valid_frac = 0.2\n",
        "valid_size = int(valid_frac * df.filename.nunique())\n",
        "train_size = df.filename.nunique() - valid_size\n",
        "valid_df = df.loc[df.filename.isin(df.filename.sample(valid_size))]\n",
        "train_df = df.loc[df.filename.isin(valid_df.filename.unique())==False]\n",
        "\n",
        "train_df.to_csv('train_labels.csv', index_label=False, index=False)\n",
        "valid_df.to_csv('test_labels.csv', index_label=False, index=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTL1aYLogzqz"
      },
      "source": [
        "#@title Buat file TFrecord Tensorflow { vertical-output: true, display-mode: \"form\" }\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "\n",
        "# Buat file `train.record`\n",
        "!python generate_tfrecord-$Versi_Tensorflow-.py --csv_input=$Pendeteksi/$Nama_Folder_Anotasi/train_labels.csv --output_path=$Pendeteksi/$Nama_Folder_Anotasi/train.record --img_path=$Pendeteksi/gambar --label_map $Pendeteksi/$Nama_Folder_Anotasi/label_map.pbtxt\n",
        "# Buat file `test.record`\n",
        "!python generate_tfrecord-$Versi_Tensorflow-.py --csv_input=$Pendeteksi/$Nama_Folder_Anotasi/test_labels.csv --output_path=$Pendeteksi/$Nama_Folder_Anotasi/test.record --img_path=$Pendeteksi/gambar --label_map $Pendeteksi/$Nama_Folder_Anotasi/label_map.pbtxt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPJEdz2yfUoG"
      },
      "source": [
        "## 3. Konfigurasi *training pipeline*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgQpEtylKwug"
      },
      "source": [
        "#@title Pilih jenis *pre trained model* yang akan digunakan dan buat nama folder untuk *training*! { vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 1\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },\n",
        "    'ssd_mobilenet_small_v3': {\n",
        "        'model_name': 'ssd_mobilenet_v3_small_coco_2019_08_14',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v3_small_320x320_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_inception_v2_coco': {\n",
        "        'model_name': 'ssd_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'ssd_inception_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'ssd_mobilenet_large_v3': {\n",
        "        'model_name': 'ssd_mobilenet_v3_large_coco_2019_08_14',\n",
        "        'pipeline_file': 'ssdlite_mobilenet_v3_large_320x320_coco.config',\n",
        "        'batch_size': 512\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pilih model yang akan Anda gunakan \n",
        "# Pilih model di dalam `MODELS_CONFIG`.\n",
        "pre_trained_model = \"faster_rcnn_inception_v2\" #@param [\"ssd_mobilenet_v2\", \"faster_rcnn_inception_v2\", \"ssd_inception_v2_coco\"] {allow-input: true}\n",
        "\n",
        "\n",
        "# Nama objek detection model yang digunakan.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# NAma file pipeline pada Tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fit di dalam Colab Tesla K80 GPU memory untuk model yang di pilih.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']\n",
        "\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "\n",
        "folder_training = \"training\" #@param {type:\"string\"}\n",
        "# Menghapus output konten sebelumnya agar mulai dari fresh kembali (Optional)\n",
        "!rm -rf {folder_training}\n",
        "os.makedirs(folder_training, exist_ok=True)\n",
        "\n",
        "%cd /content/drive/MyDrive/pendeteksi-objek/models/research\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "os.makedirs('selected_model', exist_ok=True)\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/drive/MyDrive/pendeteksi-objek/models/research/selected_model/'+selected_model\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwFDClJlhoio"
      },
      "source": [
        "#@title Konfigurasi *pipeline* { vertical-output: true, display-mode: \"form\" }\n",
        "test_record_fname = '/content/drive/MyDrive/pendeteksi-objek/'+Pendeteksi+'/'+Nama_Folder_Anotasi+'/test.record'\n",
        "train_record_fname = '/content/drive/MyDrive/pendeteksi-objek/'+Pendeteksi+'/'+Nama_Folder_Anotasi+'/train.record'\n",
        "label_map_pbtxt_fname = '/content/drive/MyDrive/pendeteksi-objek/'+Pendeteksi+'/'+Nama_Folder_Anotasi+'/label_map.pbtxt'\n",
        "\n",
        "import os\n",
        "pipeline_fname = os.path.join('/content/drive/MyDrive/pendeteksi-objek/models/research/object_detection/samples/configs', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "num_classes = get_num_classes('/content/drive/MyDrive/pendeteksi-objek/Masker/annotations/label_map.pbtxt')\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord file train dan test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set jumlah classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    # Set jumlah contoh (jumlah gambar).\n",
        "    s = re.sub('num_examples: [0-9]+',\n",
        "               'num_examples: {}'.format(num_examples), s)\n",
        "    \n",
        "\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLEaMzc-ShN"
      },
      "source": [
        "## 4. *Transfer Learning* dan *Monitoring*\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWb4Yg0qWyOT"
      },
      "source": [
        "#@title Inisialisasi Tensorboard { vertical-output: true, display-mode: \"form\" }\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "\n",
        "LOG_DIR = folder_training\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JphTUj5gXPRu"
      },
      "source": [
        "#@title *Monitoring* menggunakan *link* dibawah ini { vertical-output: true, display-mode: \"form\" }\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awwWCwarYEkj"
      },
      "source": [
        "%cd /content/drive/MyDrive/pendeteksi-objek\n",
        "#@title Mulai *Training* { vertical-output: true, display-mode: \"form\" }\n",
        "# Jumlah training step.\n",
        "num_steps =  1000000#@param {type:\"integer\"}\n",
        "\n",
        "# Jumlah evaluation step.\n",
        "num_eval_steps =  50#@param {type:\"integer\"}\n",
        "\n",
        "# Jumlah sample di dalam folder \"test\".\n",
        "num_examples =  45#@param {type:\"integer\"}\n",
        "\n",
        "!python /content/drive/MyDrive/pendeteksi-objek/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={folder_training} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-G4Lo6cW0UB"
      },
      "source": [
        "## 5. Pengujian pendeteksi objek pada gambar menggunakan *checkpoint*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6o0DSk0W7nq"
      },
      "source": [
        "## 6. Pembuatan *Inference Graph* dari data *training*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpVmRi2PskMS"
      },
      "source": [
        "#@title Buat folder untuk menyimpan *inference graph!* { vertical-output: true, display-mode: \"form\" }\n",
        "Nama_Folder_Inference_Graph = \"graph1\" #@param {type:\"string\"}\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "lst = os.listdir(folder_training)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(folder_training, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/drive/MyDrive/pendeteksi-objek/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory=/content/drive/MyDrive/pendeteksi-objek/inference_graph/$Nama_Folder_Inference_Graph \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO2rfQ2_-Uoe"
      },
      "source": [
        "# **D. PENYEBARAN *(DEPLOYMENT)***\n",
        "\n",
        "> File *inference graph* yang telah diperoleh pada tahap *training* akan dibaca pada program sistem pendeteksi objek untuk mengenali pola gambar yang telah ditentukan\n",
        "\n",
        ">Berikut merupakan *prototype* sistem pendeteksi objek yang dapat bekerja secara *realtime* menggunakan webcam\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbaKfbOxQCwi"
      },
      "source": [
        "#@title Object Detector { vertical-output: true, display-mode: \"form\" }\n",
        "Nama_Folder_Inference_Graph = \"graph1\" #@param {type:\"string\"}\n",
        "Pendeteksi = \"Masker\" #@param [\"Masker\", \"Bola\", \"Handphone\"] {allow-input: true}\n",
        "Nama_Folder_Anotasi = \"annotations\" #@param {type:\"string\"}\n",
        "\n",
        "# NOTE: Pieces taken from https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\n",
        "# The github.com/tensorflow/models is distributed under the Apache 2.0 license.\n",
        "\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import base64 \n",
        "import html\n",
        "import io\n",
        "import time\n",
        "\n",
        "# setup path so that model can be found.\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/pendeteksi-objek/models/research/object_detection')\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils\n",
        "\n",
        "# Taken from https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=SucxddsPhOmj\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "import numpy\n",
        "import PIL.Image\n",
        "\n",
        "checkpoint_name = '/content/drive/MyDrive/pendeteksi-objek/'+Nama_Folder_Inference_Graph\n",
        "#checkpoint = '{0}.ckpt'.format(checkpoint_name)\n",
        "\n",
        "with tf.get_default_graph().as_default() as graph:  \n",
        "\n",
        "  # This section builds a \"graph\" in TensorFlow to explain how to process the data.\n",
        "  jpeg_input_tensor = tf.placeholder(tf.string, ())  # We will provide a JPEG to TF.\n",
        "\n",
        "  # First, instruct TF to decode the JPEG string into a matrix.\n",
        "  image = tf.image.decode_image(jpeg_input_tensor)\n",
        "  image_tensor = tf.expand_dims(image, 0)\n",
        "\n",
        "  # Load the  graph from disk.\n",
        "  ssd_graph = tf.GraphDef()\n",
        "  with open('{}/frozen_inference_graph.pb'.format(checkpoint_name), 'rb') as f:\n",
        "    ssd_graph.ParseFromString(f.read())\n",
        "    \n",
        "  # Tell TensorFlow we would like to inspect these parts of the network.\n",
        "  output_names = ['num_detections:0', \n",
        "                  'detection_boxes:0', \n",
        "                  'detection_scores:0',\n",
        "                  'detection_classes:0']\n",
        "  ops = dict(zip(output_names, tf.graph_util.import_graph_def(\n",
        "      ssd_graph, \n",
        "      input_map={'image_tensor': image_tensor},\n",
        "      return_elements=output_names)))\n",
        "    \n",
        "  # Also extract the decoded image from the network to draw bounding boxes.\n",
        "  ops['image'] = image\n",
        "\n",
        "\n",
        "\n",
        "def run_detection(sess, img):\n",
        "  \"\"\"Run one detection round.\"\"\"\n",
        "  output_dict = sess.run(ops, feed_dict={jpeg_input_tensor: img})\n",
        "\n",
        "  # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "  output_dict['num_detections'] = int(output_dict['num_detections:0'][0])\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes:0'][0].astype(numpy.int64)\n",
        "  output_dict['detection_boxes'] = output_dict['detection_boxes:0'][0]\n",
        "  output_dict['detection_scores'] = output_dict['detection_scores:0'][0]\n",
        "  \n",
        "  return output_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap('/content/drive/MyDrive/pendeteksi-objek/'+Pendeteksi+'/'+Nama_Folder_Anotasi+'/label_map.pbtxt',\n",
        "    use_display_name=True)\n",
        "    \n",
        "with tf.Session() as sess:\n",
        "  start_input()\n",
        "\n",
        "  label_html = 'Detctioning'\n",
        "  img_data = ''\n",
        "  while True:\n",
        "    capture_start = time.time()\n",
        "    js_reply = take_photo(label_html, img_data)\n",
        "    capture_end = time.time()\n",
        "    if not js_reply:\n",
        "      break\n",
        "\n",
        "    # Javascript returns a data URL, like:\n",
        "    #     data: image/jpeg;base64,<base-64 encoded data>\n",
        "    # To use the image, decode the base-64 encoded part and treat it as a JPEG.\n",
        "    jpeg_input = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    result = run_detection(sess, jpeg_input)\n",
        "    detect_end = time.time()\n",
        "    \n",
        "    # To reduce transfer sizes, we send just the bounding boxes drawn on a \n",
        "    # transparent PNG. Here, we create a blank PNG.\n",
        "    rgb_shape = result['image'].shape\n",
        "    rgba_shape = list(rgb_shape)[0:2] + [4]\n",
        "    image_np = numpy.zeros(rgba_shape, dtype=numpy.uint8)\n",
        "    \n",
        "    # Draw the bounding boxes in the RGB channels.\n",
        "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np[:, :, 0:3],  # sub-select RGB channels only; alpha is done below.\n",
        "      result['detection_boxes'],\n",
        "      result['detection_classes'],\n",
        "      result['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=result.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=3)\n",
        "    \n",
        "    # To be visible, the alpha channel also needs to be edited. Set the alpha\n",
        "    # channel to 255 (fully opaque) wherever anything was drawn.\n",
        "    image_t = image_np.transpose()\n",
        "    max_color = numpy.maximum(numpy.maximum(image_t[0], image_t[1]), image_t[2])\n",
        "    image_t[3] = numpy.clip(max_color, 0, 1) * 255\n",
        "    viz_end = time.time()\n",
        "\n",
        "    # Save the image as a PNG in memory and assemble a data URL.\n",
        "    im = PIL.Image.fromarray(image_np, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    im.save(iobuf, format='png')\n",
        "    img_data = 'data:image/png;base64,{}'.format(\n",
        "      (str(base64.b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "    perf_measures = {\n",
        "        'server': (\n",
        "            ('take_photo', capture_end - capture_start),\n",
        "            ('run_detection', detect_end - capture_end),\n",
        "            ('visualize', viz_end - detect_end)\n",
        "        ),\n",
        "        'js': (\n",
        "            ('create', js_reply['create']),\n",
        "            ('show', js_reply['show']),\n",
        "            ('capture', js_reply['capture']),\n",
        "        ),\n",
        "    }\n",
        "    \n",
        "    label_text = 'img size: {}b\\ntime:\\n  server: {}\\n  js: {}'.format(\n",
        "        len(js_reply['img']),\n",
        "        ', '.join('{}: {:2.3f}s'.format(*x) for x in perf_measures['server']),\n",
        "        ', '.join('{}: {:2.3f}s'.format(x[0], x[1] / 1000) for x in perf_measures['js']),\n",
        "    )\n",
        "    \n",
        "    label_html = html.escape(label_text).replace('\\n', '<br/>')\n",
        "\n",
        "print('Finished')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XF-Z5NIm92i"
      },
      "source": [
        "\n",
        "\n",
        "#**Sumber Referensi**\n",
        "\n",
        "```\n",
        "Mart\\’\\in~Abadi, Ashish~Agarwal, Paul~Barham, Eugene~Brevdo, Zhifeng~Chen, Craig~Citro, … Xiaoqiang~Zheng. (2015). {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems.\n",
        "\n",
        "Skalski, P. (2019). Make Sense.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}